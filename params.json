{"name":"The Future of Music","tagline":"Data Science - CS109 Project","body":"### Where it all began\r\n\r\n<img src=\"images/intro_image.jpg\" alt=\"intro_image\" class=\"inline\"/>\r\n\r\nMusic is a huge part of our lives - from popular radio stations to our favorite artists, listening to music has not only become a source of relaxation and pleasure but a passion. We wanted to explore this area and dissect what makes some music, songs/artists more popular than others, to be able to predict the popularity of a song. \r\n\r\n<img src=\"images/echonestlogo.png\" alt=\"echonestlogo\" class=\"inline\"/>\r\n\r\nThe source of our data is an API service called Echo Nest. They provide a wide coverage of data on detailed song information from millions of artists. Because of the diverse feature set they provide, we decided their data would best suit our inquiry as to what aspects of songs most strongly affect their popularity. \r\n\r\n### Project Goals\r\n\r\nWe wanted to be able to predict the popularity of a song from its intrinsic aspects - that is, are songs with fast tempos more likely to be popular? Put together, do all these \"popularity-inducing\" aspects of a song make a song popular? Or is there something more in the picture? \r\n\r\nTo that end, we assessed our performance by whether or not we could predict whether a song made it to the Billboard Top 100. To that end, we wanted to measure how features such as tempo, song length, lyrics, genre, energy, and much more contributed to popularity on a national level. \r\n\r\n### Taking a Look at Our Data\r\n\r\nWhen we attempted to take an initial look at our data, we found some interesting results. The genre distribution, for instance, was heavily skewed towards studio, vocal, and electric categories. \r\n\r\n<img src=\"images/song_genres.png\" alt=\"song_genres\" class=\"inline\"/>\r\n\r\nWhen we looked at the feature distribution, we mostly found normal distributions, nothing too crazy. Unfortunately, when we did a pairwise correlation plot between the features and colored the Top 100 different, we found that it was very difficult to distinguish the data points. This will have to be something we keep in mind moving forward. \r\n\r\nTODO: Add in stuff here, IF WE HAVE TIME\r\n\r\n### Initial Modelling\r\n\r\nTODO: What is our baseline?\r\n\r\nTODO: Talk about Ridge Regression\r\n\r\nSimilarly, we attempted a Linear SVM. Unfortunately, as we noted from doing pre-analysis visualization of the song features, our features aren't easily linearly separable; what this entails is that finding a decision boundary by which to distinguish songs in the top 100 from songs not in the top 100. When we attempted this method, we found that it performed no better than the baseline. \r\n\r\nWhat surprised us was the result from Random Forest. Even though this method revolves around using decision trees, it too wasn't performing better than the baseline. What this tells is that there are issues with our labelling or issues with our sample, since its indicative that our random forest decided the most optimal strategy was to predict negatively. \r\n\r\nTODO: Talk about other methods\r\n\r\n### Adding Lyrics to the Equation\r\n\r\nTODO: Talk about Lyrics\r\n\r\n### Advanced Modeling\r\n\r\nTODO: Do we even have these?\r\n\r\n### Our Results\r\n\r\nThis project highlighted a few important topics, the first being \r\n\r\nTODO: list our conclusions\r\n\r\n### Authors and Contributors\r\nIf you have questions or concerns, please message Allen Chen (@allenchen248), Richard Wang (lmetatron), or Jesse Chen (@chenje16).\r\n\r\n### Data\r\nThe data that we used for our project can be found here: TODO: insert Dropbox link to our data here (required by project spec)\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}